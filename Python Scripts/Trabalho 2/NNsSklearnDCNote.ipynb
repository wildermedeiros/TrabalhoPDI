{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python392jvsc74a57bd01564ab7a8a14d1fa39d9d42dbe913f960e04be420fae7be3f6a9326a9f4f2f89",
   "display_name": "Python 3.9.2 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "1564ab7a8a14d1fa39d9d42dbe913f960e04be420fae7be3f6a9326a9f4f2f89"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Iteration 1, loss = 0.68393214\n",
      "Iteration 2, loss = 0.65703878\n",
      "Iteration 3, loss = 0.65139573\n",
      "Iteration 4, loss = 0.65060507\n",
      "Iteration 5, loss = 0.65019956\n",
      "Iteration 6, loss = 0.64912689\n",
      "Iteration 7, loss = 0.64920459\n",
      "Iteration 8, loss = 0.64840577\n",
      "Iteration 9, loss = 0.64879668\n",
      "Iteration 10, loss = 0.64986024\n",
      "Iteration 11, loss = 0.64815360\n",
      "Iteration 12, loss = 0.64747948\n",
      "Iteration 13, loss = 0.64762761\n",
      "Iteration 14, loss = 0.64825586\n",
      "Iteration 15, loss = 0.64777283\n",
      "Iteration 16, loss = 0.64772183\n",
      "Iteration 17, loss = 0.64714785\n",
      "Iteration 18, loss = 0.64732826\n",
      "Iteration 19, loss = 0.64614072\n",
      "Iteration 20, loss = 0.64585843\n",
      "Iteration 21, loss = 0.64624539\n",
      "Iteration 22, loss = 0.64617318\n",
      "Iteration 23, loss = 0.64655792\n",
      "Iteration 24, loss = 0.64609357\n",
      "Iteration 25, loss = 0.64559757\n",
      "Iteration 26, loss = 0.64601594\n",
      "Iteration 27, loss = 0.64588336\n",
      "Iteration 28, loss = 0.64653502\n",
      "Iteration 29, loss = 0.64697714\n",
      "Iteration 30, loss = 0.64472596\n",
      "Iteration 31, loss = 0.64503758\n",
      "Iteration 32, loss = 0.64429435\n",
      "Iteration 33, loss = 0.64404057\n",
      "Iteration 34, loss = 0.64483619\n",
      "Iteration 35, loss = 0.64523605\n",
      "Iteration 36, loss = 0.64434563\n",
      "Iteration 37, loss = 0.64454914\n",
      "Iteration 38, loss = 0.64391489\n",
      "Iteration 39, loss = 0.64435263\n",
      "Iteration 40, loss = 0.64465355\n",
      "Iteration 41, loss = 0.64395106\n",
      "Iteration 42, loss = 0.64354883\n",
      "Iteration 43, loss = 0.64374709\n",
      "Iteration 44, loss = 0.64399883\n",
      "Iteration 45, loss = 0.64364075\n",
      "Iteration 46, loss = 0.64370752\n",
      "Iteration 47, loss = 0.64339380\n",
      "Iteration 48, loss = 0.64289330\n",
      "Iteration 49, loss = 0.64358606\n",
      "Iteration 50, loss = 0.64328925\n",
      "Iteration 51, loss = 0.64298947\n",
      "Iteration 52, loss = 0.64333667\n",
      "Iteration 53, loss = 0.64324233\n",
      "Iteration 54, loss = 0.64277026\n",
      "Iteration 55, loss = 0.64338699\n",
      "Iteration 56, loss = 0.64223776\n",
      "Iteration 57, loss = 0.64324228\n",
      "Iteration 58, loss = 0.64218043\n",
      "Iteration 59, loss = 0.64242885\n",
      "Iteration 60, loss = 0.64271576\n",
      "Iteration 61, loss = 0.64236543\n",
      "Iteration 62, loss = 0.64232997\n",
      "Iteration 63, loss = 0.64248579\n",
      "Iteration 64, loss = 0.64225371\n",
      "Iteration 65, loss = 0.64195512\n",
      "Iteration 66, loss = 0.64298571\n",
      "Iteration 67, loss = 0.64352460\n",
      "Iteration 68, loss = 0.64283456\n",
      "Iteration 69, loss = 0.64202297\n",
      "Iteration 70, loss = 0.64444155\n",
      "Iteration 71, loss = 0.64249892\n",
      "Iteration 72, loss = 0.64191887\n",
      "Iteration 73, loss = 0.64180676\n",
      "Iteration 74, loss = 0.64145984\n",
      "Iteration 75, loss = 0.64147185\n",
      "Iteration 76, loss = 0.64113000\n",
      "Iteration 77, loss = 0.64183992\n",
      "Iteration 78, loss = 0.64181582\n",
      "Iteration 79, loss = 0.64123355\n",
      "Iteration 80, loss = 0.64176735\n",
      "Iteration 81, loss = 0.64119622\n",
      "Iteration 82, loss = 0.64134155\n",
      "Iteration 83, loss = 0.64166012\n",
      "Iteration 84, loss = 0.64192587\n",
      "Iteration 85, loss = 0.64135284\n",
      "Iteration 86, loss = 0.64148429\n",
      "Iteration 87, loss = 0.64057096\n",
      "Iteration 88, loss = 0.64108416\n",
      "Iteration 89, loss = 0.64114025\n",
      "Iteration 90, loss = 0.64068049\n",
      "Iteration 91, loss = 0.64082531\n",
      "Iteration 92, loss = 0.64032496\n",
      "Iteration 93, loss = 0.64040382\n",
      "Iteration 94, loss = 0.64036395\n",
      "Iteration 95, loss = 0.64023274\n",
      "Iteration 96, loss = 0.64085170\n",
      "Iteration 97, loss = 0.64003765\n",
      "Iteration 98, loss = 0.64002956\n",
      "Iteration 99, loss = 0.64059811\n",
      "Iteration 100, loss = 0.64018547\n",
      "[[2856 1279]\n",
      " [1880 2217]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.60      0.69      0.64      4135\n",
      "         2.0       0.63      0.54      0.58      4097\n",
      "\n",
      "    accuracy                           0.62      8232\n",
      "   macro avg       0.62      0.62      0.61      8232\n",
      "weighted avg       0.62      0.62      0.61      8232\n",
      "\n",
      "G:\\Python\\Python 3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "data = genfromtxt(\n",
    "    \"C:/Users/Usuario/Downloads/PDI Exercicios/Python Scripts/datasetTest/data.txt\", delimiter=',')\n",
    "\n",
    "labels = data[:, 12]\n",
    "features = data[:, 0:12]\n",
    "\n",
    "X = features\n",
    "y = labels\n",
    "\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "scalerObject = MinMaxScaler()\n",
    "\n",
    "scalerObject.fit(XTrain)\n",
    "\n",
    "scaledXTrain = scalerObject.transform(XTrain)\n",
    "scaledXTest = scalerObject.transform(XTest)\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(42, 42), activation='relu', solver='adam', max_iter=100, verbose=2)\n",
    "\n",
    "mlp.fit(scaledXTrain, yTrain)\n",
    "\n",
    "predictions = mlp.predict(scaledXTest)\n",
    "\n",
    "print(confusion_matrix(yTest, predictions))\n",
    "\n",
    "print(classification_report(yTest, predictions))\n"
   ]
  }
 ]
}